{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.config import Config\n",
    "from utils.data import SEED\n",
    "from utils.data import C as IC\n",
    "from utils.data import H as IH\n",
    "from utils.data import W as IW\n",
    "from utils.data import (data_import, img_add_label, img_plot, change_range,\n",
    "                        test_data_import, img_save, img_read, batch_loader,\n",
    "                        img_crop_by_label, subtitle_recognition)\n",
    "from utils.video_editor import THRESH, pics_merge_into_video, video_split\n",
    "from utils.common import touch_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = Config()\n",
    "MODEL_FILE = CONFIG['model_file']\n",
    "TEST_IMG_DIR = touch_dir(CONFIG['test_video_imgs_dir'])\n",
    "TEST_VIDEO = CONFIG['test_video']\n",
    "CROP_IMGS_DIR = touch_dir(CONFIG['crop_imgs_dir'])\n",
    "LABEL_IMGS_DIR = touch_dir(CONFIG['label_imgs_dir'])\n",
    "TEST_CACHE = CONFIG['test_cache']\n",
    "TEST_OUT_VIDEO = CONFIG['test_out_video']\n",
    "SUBTITLES_TXT = CONFIG['subtitles_txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss and Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBoxError(tf.keras.losses.Loss):\n",
    "    \"\"\" BoundingBox Loss 函数 \"\"\"\n",
    "    def __init__(self, weights=[1, 1, 1, 1, 1]):\n",
    "        \"\"\" 输出 5 元 Vector，各个维度分别为 [pc, bx, by, bh, bw] \"\"\"\n",
    "        super().__init__()\n",
    "        self.weights = np.array(weights)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # 如果不包含目标\n",
    "        # loss_1 = (1 - y_true[:, 0]) * self.weights[0] * (y_true[:, 0] - y_pred[:, 0])**2\n",
    "        loss_1 = (1 - y_true[:, 0]) * self.weights[0] * (-tf.math.log(1-y_pred[:, 0]+1e-10))\n",
    "        # 如果包含目标，回归项\n",
    "        # loss_2_logis = y_true[:, 0] * self.weights[0] * (y_true[:, 0] - y_pred[:, 0])**2\n",
    "        loss_2_logis = y_true[:, 0] * self.weights[0] * (-tf.math.log(y_pred[:, 0]+1e-10))\n",
    "        # 如果包含目标，定位项\n",
    "        loss_2_square = y_true[:, 0] * tf.reduce_sum(self.weights[1: ] * (y_true[:, 1: ] - y_pred[:, 1: ])**2, axis=-1)\n",
    "        return tf.reduce_mean(loss_1 + loss_2_logis + loss_2_square)\n",
    "\n",
    "class IOUMeanMetric(tf.keras.metrics.Metric):\n",
    "    \"\"\" 交并比评估器 \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.iou_sum = self.add_weight(name='iou_sum', dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "        self.total = self.add_weight(name='total', dtype=tf.int32, initializer=tf.zeros_initializer())\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        bx1, by1, bh1, bw1 = y_true[:, 1], y_true[:, 2], y_true[:, 3], y_true[:, 4]\n",
    "        bx2, by2, bh2, bw2 = y_pred[:, 1], y_pred[:, 2], y_pred[:, 3], y_pred[:, 4]\n",
    "        cross_w = tf.minimum(bx1+bw1/2, bx2+bw2/2) - tf.maximum(bx1-bw1/2, bx2-bw2/2)\n",
    "        cross_h = tf.minimum(by1+bh1/2, by2+bh2/2) - tf.maximum(by1-bh1/2, by2-bh2/2)\n",
    "        mask = tf.cast(cross_w > 0, tf.float32) * tf.cast(cross_h > 0, tf.float32) * y_true[:, 0]\n",
    "        s1 = bh1 * bw1\n",
    "        s2 = bh2 * bw2\n",
    "        sc = cross_w * cross_h\n",
    "        iou = mask * sc / (s1 + s2 - sc)\n",
    "        self.iou_sum.assign_add(tf.reduce_sum(iou))\n",
    "        self.total.assign_add(tf.cast(tf.reduce_sum(y_true[:, 0]), dtype=tf.int32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.iou_sum / tf.cast(self.total, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.DenseNet121(input_shape=(IH, IW, IC), weights='imagenet', include_top=False)\n",
    "# base_model.trainable = False\n",
    "inputs = tf.keras.Input(shape=(IH, IW, IC))\n",
    "x = inputs\n",
    "x = base_model(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(5)(x)\n",
    "# x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# x = tf.keras.layers.Dense(5)(x)\n",
    "outputs = tf.keras.layers.Activation('sigmoid')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weights\n",
    "model.load_weights(MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "aug = iaa.SomeOf((0, 5), [\n",
    "        iaa.OneOf([\n",
    "            iaa.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n",
    "            iaa.AverageBlur(k=(2, 3)), # blur image using local means with kernel sizes between 2 and 7\n",
    "            iaa.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "        ]),\n",
    "        iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
    "        iaa.Emboss(alpha=(0, 1.0), strength=(0, 1.0)), # emboss images\n",
    "        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
    "        iaa.OneOf([\n",
    "            iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "            iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n",
    "        ]),\n",
    "        iaa.Invert(0.05, per_channel=True), # invert color channels\n",
    "        iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "        iaa.AddToHueAndSaturation((-20, 20)), # change hue and saturation\n",
    "        # either change the brightness of the whole image (sometimes\n",
    "        # per channel) or change the brightness of subareas\n",
    "        iaa.LinearContrast((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n",
    "        iaa.Grayscale(alpha=(0.0, 1.0)),\n",
    "        sometimes(iaa.ElasticTransformation(alpha=(0.5, 2), sigma=0.1)), # move pixels locally around (with random strengths)\n",
    "        sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.03))), # sometimes move parts of the image around\n",
    "    ], random_order=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_import()\n",
    "X, y = data_set['X'], data_set['Y']\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.05, random_state=SEED)\n",
    "test_data_set = test_data_import()\n",
    "X_test = test_data_set['X']\n",
    "train_size, dev_size, test_size = X_train.shape[0], X_dev.shape[0], X_test.shape[0]\n",
    "print(\"训练集数据 {} 条，开发集数据 {} 条，测试集数据 {} 条\".format(train_size, dev_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "batch_size = 16\n",
    "learning_rate = 3e-5\n",
    "use_gpu = True\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss_object = BBoxError([1, 2, 5, 1, 3])\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_iou = IOUMeanMetric()\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_iou = IOUMeanMetric()\n",
    "\n",
    "# GPU Config\n",
    "if use_gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_check_imgs = 10\n",
    "X_batch, y_batch = next(batch_loader(X_train, y_train, batch_size=num_check_imgs))\n",
    "X_batch_aug = aug(images=X_batch)\n",
    "y_batch_pred = model(change_range(X_batch)).numpy()\n",
    "\n",
    "for idx in range(num_check_imgs):\n",
    "    img_aug = X_batch_aug[idx]\n",
    "    img = X_batch[idx]\n",
    "    label = y_batch[idx]\n",
    "    label_pred = y_batch_pred[idx]\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Origin Image')\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Augmented Image')\n",
    "    plt.imshow(img_aug)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    img_with_label = img_add_label(img, label, color=(255, 0, 0))\n",
    "    img_with_label = img_add_label(img_with_label, label_pred, color=(0, 0, 255))\n",
    "    plt.title('Origin Image with Label')\n",
    "    plt.imshow(img_with_label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_on_batch(X_batch, y_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X_batch, training=True)\n",
    "        loss = loss_object(y_true=y_batch, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_iou(y_batch, y_pred)\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def test_on_batch(X_batch, y_batch):\n",
    "    y_pred = model(X_batch, training=False)\n",
    "    t_loss = loss_object(y_batch, y_pred)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_iou(y_batch, y_pred)\n",
    "    return t_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_iou.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_iou.reset_states()\n",
    "\n",
    "    # Training\n",
    "    for batch_index, (X_batch, y_batch) in enumerate(batch_loader(X_train, y_train, batch_size=batch_size)):\n",
    "        X_batch = np.array(aug(images=X_batch))\n",
    "        X_batch = change_range(X_batch)\n",
    "        loss = train_on_batch(X_batch, y_batch)\n",
    "        template = '[Training] Epoch {}, Batch {}/{}, Loss: {}, IOU: {:.2%} '\n",
    "        print(template.format(epoch+1,\n",
    "                            batch_index,\n",
    "                            train_size // batch_size,\n",
    "                            loss,\n",
    "                            train_iou.result()),\n",
    "            end='\\r')\n",
    "\n",
    "    # Testing\n",
    "    for batch_index, (X_batch, y_batch) in enumerate(batch_loader(X_dev, y_dev, batch_size=batch_size)):\n",
    "        X_batch = change_range(X_batch)\n",
    "        loss = test_on_batch(X_batch, y_batch)\n",
    "        template = '[Testing] Epoch {}, Batch {}/{}, Loss: {}, IOU: {:.2%} '\n",
    "        print(template.format(epoch+1,\n",
    "                            batch_index,\n",
    "                            test_size // batch_size,\n",
    "                            loss,\n",
    "                            test_iou.result()),\n",
    "            end='\\r')\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, IOU: {:.2%}, Test Loss: {}, Test IOU: {:.2%} '\n",
    "    print(template.format(epoch+1,\n",
    "                        train_loss.result(),\n",
    "                        train_iou.result(),\n",
    "                        test_loss.result(),\n",
    "                        test_iou.result()))\n",
    "\n",
    "    model.save_weights(MODEL_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encodings = model(change_range(X_test))\n",
    "for i in range(test_size):\n",
    "    img_path = test_data_set[\"img_paths\"][i]\n",
    "    img = img_read(img_path)\n",
    "    label = encodings[i].numpy()\n",
    "    print(label)\n",
    "    img_plot(img_add_label(img, label, noise=(0, 0)), shape=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vedio Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyframe_id_set = video_split(TEST_VIDEO, TEST_IMG_DIR, only_keyframes=False, compute_keyframe=THRESH)\n",
    "video_test_data_set = test_data_import(test_img_dir=TEST_IMG_DIR, cache=None)\n",
    "num_test_imgs = len(video_test_data_set[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前向传播获取编码向量\n",
    "encodings = np.zeros((num_test_imgs, *outputs.shape[1: ]), dtype=np.float64)\n",
    "for i in range(0, num_test_imgs, batch_size):\n",
    "    print(\"encoding {}/{} \".format(i, num_test_imgs), end=\"\\r\")\n",
    "    X_batch = video_test_data_set[\"X\"][i: i+batch_size]\n",
    "    X_batch = change_range(X_batch)\n",
    "    encodings_batch = model(X_batch)\n",
    "    encodings[i: i+batch_size] = encodings_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对图片打标签并裁剪出字幕区域\n",
    "for i in range(num_test_imgs):\n",
    "    signs = [\">>   \", \" >>  \", \"  >> \", \"   >>\"]\n",
    "    print(\"{} {:6d}/{} \".format(signs[i%len(signs)], i, num_test_imgs), end=\"\\r\")\n",
    "    img_path = video_test_data_set[\"img_paths\"][i]\n",
    "    img_name = os.path.basename(img_path)\n",
    "    img = img_read(img_path)\n",
    "    crop_img_path = os.path.join(CROP_IMGS_DIR, img_name)\n",
    "    label_img_path = os.path.join(LABEL_IMGS_DIR, img_name)\n",
    "\n",
    "    label = encodings[i]\n",
    "    if i in keyframe_id_set:\n",
    "        crop_area = img_crop_by_label(img, label, noise=(0.05, 0.05))\n",
    "        if crop_area is not None:\n",
    "            img_save(crop_area, crop_img_path)\n",
    "    img_with_label = img_add_label(img, label, noise=(0.05, 0.05))\n",
    "    img_save(img_with_label, label_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将打好标签的帧合并成视频\n",
    "pics_merge_into_video(TEST_OUT_VIDEO, LABEL_IMGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用百度 AIP 识别字幕\n",
    "subtitles = subtitle_recognition(CROP_IMGS_DIR)\n",
    "with open(SUBTITLES_TXT, \"w\", encoding=\"utf8\") as f:\n",
    "    for subtitle in subtitles:\n",
    "        f.write(subtitle + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}